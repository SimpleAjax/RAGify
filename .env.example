# =============================================================================
# RAGify Configuration - Model Settings
# Copy this file to .env and fill in your API keys
# =============================================================================

# -----------------------------------------------------------------------------
# API Keys (Required)
# -----------------------------------------------------------------------------

# OpenRouter API Key (recommended) - Get from https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-api-key-here

# Alternative: OpenAI API Key (if using OpenAI directly)
# OPENAI_API_KEY=sk-your-openai-key-here

# -----------------------------------------------------------------------------
# EMBEDDING MODELS (Local - FREE)
# -----------------------------------------------------------------------------

# HuggingFace Embedding Model for Vector Search
# Options:
#   - BAAI/bge-small-en-v1.5  (384 dims, fast, default)
#   - BAAI/bge-large-en-v1.5  (1024 dims, better quality)
#   - sentence-transformers/all-MiniLM-L6-v2 (384 dims, popular)
EMBEDDING_MODEL_NAME=BAAI/bge-small-en-v1.5

# -----------------------------------------------------------------------------
# RAGAS EVALUATION MODEL (Called frequently - use cheaper model)
# -----------------------------------------------------------------------------

# Model for RAGAS metrics evaluation (Context Precision, Recall, Faithfulness, etc.)
# Recommended: claude-3-haiku (good judge, cheap)
# Budget: mistralai/mistral-7b-instruct (cheapest)
# Premium: anthropic/claude-3.5-sonnet (best quality)
EVALUATION_MODEL=openrouter/anthropic/claude-3-haiku
EVALUATION_API_BASE=https://openrouter.ai/api/v1

# -----------------------------------------------------------------------------
# RAG STRATEGY MODELS (Query Decomposition, Entity Extraction, Generation)
# -----------------------------------------------------------------------------

# Model for Query Decomposition (structured JSON output required)
# Recommended: openai/gpt-4o-mini (best JSON adherence, cheap)
DECOMPOSITION_MODEL=openrouter/openai/gpt-4o-mini
DECOMPOSITION_API_BASE=https://openrouter.ai/api/v1

# Model for Entity Extraction in GraphRAG (NER task)
# Recommended: anthropic/claude-3-haiku (good NER, cheap)
ENTITY_EXTRACTION_MODEL=openrouter/anthropic/claude-3-haiku
ENTITY_EXTRACTION_API_BASE=https://openrouter.ai/api/v1

# Model for Answer Generation (NaiveRAG, GraphRAG final answer)
# Recommended: openai/gpt-4o-mini (good quality, low hallucination, cheap)
GENERATION_MODEL=openrouter/openai/gpt-4o-mini
GENERATION_API_BASE=https://openrouter.ai/api/v1

# Model for Agentic RAG (tool calling + reasoning)
# Recommended: anthropic/claude-3-haiku (good tool use, cheap)
AGENTIC_MODEL=openrouter/anthropic/claude-3-haiku
AGENTIC_API_BASE=https://openrouter.ai/api/v1

# -----------------------------------------------------------------------------
# ALTERNATIVE: USE SINGLE MODEL FOR ALL RAG TASKS
# -----------------------------------------------------------------------------

# Uncomment below to use one model for all RAG strategies (simpler but less optimal)
# RAG_MODEL=openrouter/openai/gpt-4o-mini
# RAG_API_BASE=https://openrouter.ai/api/v1

# -----------------------------------------------------------------------------
# PREMIUM CONFIGURATION (Best Quality - Higher Cost)
# -----------------------------------------------------------------------------

# Uncomment for premium quality (Claude 3.5 Sonnet for everything)
# EVALUATION_MODEL=openrouter/anthropic/claude-3.5-sonnet
# DECOMPOSITION_MODEL=openrouter/anthropic/claude-3.5-sonnet
# ENTITY_EXTRACTION_MODEL=openrouter/anthropic/claude-3.5-sonnet
# GENERATION_MODEL=openrouter/anthropic/claude-3.5-sonnet
# AGENTIC_MODEL=openrouter/anthropic/claude-3.5-sonnet

# -----------------------------------------------------------------------------
# BUDGET CONFIGURATION (Ultra-Low Cost)
# -----------------------------------------------------------------------------

# Uncomment for ultra-low cost (Mistral 7B for everything)
# EVALUATION_MODEL=openrouter/mistralai/mistral-7b-instruct
# DECOMPOSITION_MODEL=openrouter/mistralai/mistral-7b-instruct
# ENTITY_EXTRACTION_MODEL=openrouter/mistralai/mistral-7b-instruct
# GENERATION_MODEL=openrouter/mistralai/mistral-7b-instruct
# AGENTIC_MODEL=openrouter/mistralai/mistral-7b-instruct

# -----------------------------------------------------------------------------
# DATABASE CONFIGURATION
# -----------------------------------------------------------------------------

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=ragify_evaluator

# Neo4j Graph Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# -----------------------------------------------------------------------------
# MLFLOW CONFIGURATION
# -----------------------------------------------------------------------------

MLFLOW_EXPERIMENT_NAME=RAGify_Evaluations
MLFLOW_TRACKING_URI=./mlruns

# -----------------------------------------------------------------------------
# CHUNKING CONFIGURATION
# -----------------------------------------------------------------------------

# Text splitter settings for document chunking
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# -----------------------------------------------------------------------------
# DATASET INDEXING CONFIGURATION
# -----------------------------------------------------------------------------

# Number of samples to index from each dataset
# Set to 0 to skip a dataset, or -1 to index ALL samples
# Default: 100 (small subset for fast prototyping)

# HotpotQA (validation split has ~7,405 samples)
HOTPOTQA_SAMPLE_SIZE=100

# 2WikiMultiHopQA (train split has ~167,454 samples!)
# This dataset provides graph triples for GraphRAG
TWOWIKI_SAMPLE_SIZE=100

# MuSiQue (validation split has ~2,417 samples)
MUSIQUE_SAMPLE_SIZE=100

# MultiHop-RAG (train split has ~2,556 samples)
MULTIHOP_RAG_SAMPLE_SIZE=100

# -----------------------------------------------------------------------------
# DATASET SPLITS
# -----------------------------------------------------------------------------

# Which splits to use for each dataset
HOTPOTQA_SPLIT=validation
TWOWIKI_SPLIT=train
MUSIQUE_SPLIT=validation
MULTIHOP_RAG_SPLIT=train
